{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qVdV76wxwvU7"
   },
   "source": [
    "# Dev Setups: Connecting Python and SQL\n",
    "\n",
    "The purpose of this Jupyter notebook is to demonstrate the usefulness of connecting python to a relational database by using a python toolkit called SQLAlchemy. This tutorial follows the previous document, *** Testing Python and Data Science basic stack ***\n",
    "\n",
    "**This notebook is for Mac OS and Windows specific instructions. See `DS_sql_dev_setup_linux.ipynb` for Linux.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mh-p08VOwvVB"
   },
   "source": [
    "### First off, what is a relational database?\n",
    "\n",
    "Basically, it is a way to store information such that information can be retrieved from it.\n",
    "\n",
    "MySQL and PostgreSQL are examples of relational databases.  For the purposes of an Insight project, you can use either one.\n",
    "\n",
    "Why would you use a relational database instead of a csv or two?\n",
    "\n",
    "**A few reasons:**\n",
    "\n",
    "- They scale easily\n",
    "\n",
    "-  They are easy to query\n",
    "\n",
    "- It’s possible to do transactions in those cases where you need to write to a database, not just read from it\n",
    "\n",
    "- Everyone in industry uses them, so you should get familiar with them, too.\n",
    "\n",
    "***What does a relational database look like? ***\n",
    "\n",
    "We can take a look.  First we need to set up a few things. The first thing we want to do is to get a PostgreSQL server up and running.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MA0lAdhRwvVF"
   },
   "source": [
    "## Postgres Installation\n",
    "\n",
    "**Mac OS installation:**\n",
    "Go to http://postgresapp.com/ and follow the three steps listed in the Quick Installation Guide. \n",
    "\n",
    "**Windows OS installation:** \n",
    "Go to https://www.postgresql.org/download/windows/ to download the installer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lId9n2kbwvVI"
   },
   "source": [
    "**If you're on a mac, you might need to add psql to PATH in order to interact with Postgres in the Terminal more easily**. See this website for info on bash profiles and PATH: https://hathaway.cc/2008/06/how-to-edit-your-path-environment-variables-on-mac/<br>\n",
    "\n",
    "**Edit your .bash_profile in your home directory. Since you already installed Anaconda, it should look something like:**<br>\n",
    "```export PATH=\"/Users/YOUR_USER_NAME/anaconda/bin:$PATH\"```\n",
    "\n",
    "**Right below the line added by anaconda you can add this line:**<br>\n",
    "\n",
    "```export PATH=\"/Applications/Postgres.app/Contents/Versions/latest/bin:$PATH\"```\n",
    "\n",
    "**Save and reload the bash profile in Terminal**<br>\n",
    "``` source .bash_profile```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WegaV-rhwvVM"
   },
   "source": [
    "## Start your postgresql server\n",
    "\n",
    "**There are multiple ways to launch a postgres server. For now, let's stick with the following. **\n",
    "\n",
    "**The only user right now for PSQL is 'postgres', you can make your database and enter it with that username in the terminal.** We're using a dataset on births, so we'll call it birth_db. <br>\n",
    "``` createdb birth_db -U postgres```<br>\n",
    "``` psql birth_db```\n",
    "\n",
    "**If you want to make a new user for this database you can make one now. \n",
    "Note: username in the below line must match your Mac/Linux username:**<br>\n",
    "``` CREATE USER username SUPERUSER PASSWORD 'yourpassword'```<br>\n",
    "\n",
    "**Exit out of PSQL (\\q) and test logging in through this user:**<br>\n",
    "``` psql birth_db -h localhost -U username```<br>\n",
    "``` \\c ```  (once in PSQL to check how you're logged in)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0_PLDQiiwvVO"
   },
   "source": [
    "## Set up SQLalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ptYMkG2ZwvVR"
   },
   "source": [
    "In jupyter you can run code in the command line with the \"!\" special character as you'll see in the next cell.  We do this here for ease but it's generally considered poor practice. Run the following commands to install the necessary packages for python to talk to a sql database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aK7q_i-xwvVT"
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy_utils \n",
    "!conda install psycopg2 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTjerEwBwvVb"
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7Jt48BCwvVg"
   },
   "source": [
    "## Define and populate a database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dNEBDcoBwvVi"
   },
   "source": [
    "Run the cells below to define your new database and populate it with data from the included CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qsx54FiDwvVj"
   },
   "outputs": [],
   "source": [
    "# Define a database name \n",
    "# Set your postgres username\n",
    "dbname = 'birth_db'\n",
    "username = 'April' # change this to your username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MepdSDURwvVn"
   },
   "outputs": [],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zu_qSF4DwvVr"
   },
   "outputs": [],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y7kGAPRiwvVv"
   },
   "outputs": [],
   "source": [
    "# read a database from the included CSV and load it into a pandas dataframe\n",
    "# you may need to add a path in the command below if you aren't working in the same directory you saved the CSV\n",
    "birth_data = pd.read_csv('births2012_downsampled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RdTNIBtxwvVz"
   },
   "outputs": [],
   "source": [
    "## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "birth_data.to_sql('birth_data_table', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0JJs_3hmwvV3"
   },
   "source": [
    "The above line (to_sql) is doing a lot of heavy lifting.  It's reading a dataframe, it's creating a table, and adding the data to the table.  So ** SQLAlchemy is quite useful! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l7MY6N8WwvV4"
   },
   "source": [
    "## Working with PostgresSQL without Python\n",
    "\n",
    "**Open up the PostgreSQL app, click on the database you just created, ** <br>\n",
    "\n",
    "or alternatively type <br>\n",
    "\n",
    " ```  psql -h localhost ``` <br>\n",
    " ```  \\c birth_db ```\n",
    "\n",
    "\n",
    "into the command line  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PiLhPXLEwvV5"
   },
   "source": [
    "**You should see something like the following**\n",
    "\n",
    "`You are now connected to database \"birth_db\" as user \"April\".`\n",
    "\n",
    "\n",
    "**Then try the following query:**\n",
    "\n",
    " ```   SELECT * FROM birth_data_table; ```\n",
    "    \n",
    "Note that the semi-colon indicates an end-of-statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BF88fX0hwvV6"
   },
   "source": [
    "### You can see the table we created!  But it's kinda ugly and hard to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CkBj6WtQwvV7"
   },
   "source": [
    "Press q in your terminal at any time to get back to the command line. \n",
    "\n",
    "Try a few other sample queries.  Before you type in each one, ask yourself what you think the output will look like:\n",
    "\n",
    "`SELECT * FROM birth_data_table WHERE infant_sex='M';`\n",
    "\n",
    "`SELECT COUNT(infant_sex) FROM birth_data_table WHERE infant_sex='M';`\n",
    "\n",
    "`SELECT COUNT(gestation_weeks), infant_sex FROM birth_data_table WHERE infant_sex = 'M' GROUP BY gestation_weeks, infant_sex;`\n",
    "\n",
    "`SELECT gestation_weeks, COUNT(gestation_weeks) FROM birth_data_table WHERE infant_sex = 'M' GROUP BY gestation_weeks;`\n",
    "\n",
    "All the above queries run, but they are difficult to visually inspect in the Postgres terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ku746fYywvV8"
   },
   "source": [
    "## Working with PostgreSQL in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GyEA9rP0wvV9"
   },
   "outputs": [],
   "source": [
    "# Connect to make queries using psycopg2\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "\n",
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM birth_data_table WHERE delivery_method='Cesarean';\n",
    "\"\"\"\n",
    "birth_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "birth_data_from_sql.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ZCM1S69wvWB"
   },
   "source": [
    "Once the data has been pulled into python, we can leverage pandas methods to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHkBUNQpwvWC"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "birth_data_from_sql.hist(column='birth_weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcStgGE-wvWF"
   },
   "source": [
    "### Is reading from a SQL database faster than from a Pandas dataframe?  Probably not for the amount of data you can fit on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "397PIhVowvWG"
   },
   "outputs": [],
   "source": [
    "def get_data(sql_query, con):\n",
    "    data = pd.read_sql_query(sql_query, con)\n",
    "    return data\n",
    "\n",
    "%timeit get_data(sql_query, con)\n",
    "\n",
    "birth_data_from_sql = get_data(sql_query, con)\n",
    "birth_data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "juA1AzxywvWK"
   },
   "outputs": [],
   "source": [
    "def get_pandas_data(df, col, value):\n",
    "    sub_df = df.loc[(df[col] == value)]\n",
    "    return sub_df\n",
    "\n",
    "%timeit get_pandas_data(birth_data, 'delivery_method', 'Cesarean')\n",
    "\n",
    "birth_data_out = get_pandas_data(birth_data, 'delivery_method', 'Cesarean')\n",
    "birth_data_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsnMqNuQwvWN"
   },
   "source": [
    "This should have given you a quick taste of how to use SQLALchemy, as well as how to run a few SQL queries both at the command line and in python.  You can see that `pandas` is actually a quite a bit faster than PostgreSQL here. This is because we're working with quite a small database (2716 rows × 37 columns), and there is an overhead of time it takes to communicate between python and PostGreSQL.  But as your database gets bigger (and certainly when it's too large to store in memory), working with relational databases becomes a necessity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U5SzEHBPwvWP"
   },
   "source": [
    "#### Congrats! You now have Python and SQL ready to go!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DS_sql_setup_part_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
